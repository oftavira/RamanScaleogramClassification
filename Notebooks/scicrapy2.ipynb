{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "\n",
    "class ProxyInList:\n",
    "\n",
    "    def __init__(self, ip, port, country, anonymity, google, https, last_checked):\n",
    "        self.ip = ip\n",
    "        self.port = port\n",
    "        self.country = country\n",
    "        self.anonymity = anonymity\n",
    "        self.google = google\n",
    "        self.https = https\n",
    "        self.last_checked = last_checked\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'ip:port: ' + self.ip + ':' + self.port + ' ' + 'country: ' + self.country + ' ' + 'anonymity: ' +self.anonymity + ' ' + 'google: ' +self.google + ' ' + 'https: ' +self.https + ' ' + 'last_checked: ' + self.last_checked\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'ip:port: ' + self.ip + ':' + self.port + ' ' + 'country: ' + self.country + ' ' + 'anonymity: ' +self.anonymity + ' ' + 'google: ' +self.google + ' ' + 'https: ' +self.https + ' ' + 'last_checked: ' + self.last_checked\n",
    "    \n",
    "    # Now we set a getter for the ip and port, this allows to obtain the ip and port without calling a method and instead just calling the variable\n",
    "\n",
    "    @property\n",
    "    def ip_port(self):\n",
    "        return self.ip + ':' + self.port\n",
    "\n",
    "\n",
    "\n",
    "class Proxies:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.proxies = []\n",
    "        self.get_proxies()\n",
    "\n",
    "    def get_proxies(self):\n",
    "        proxy_page = requests.get('https://free-proxy-list.net/')\n",
    "        soup_prox = BeautifulSoup(proxy_page.content, 'html.parser')\n",
    "        prox = soup_prox.find('div', class_='table-responsive fpl-list')\n",
    "        prox2 = prox.find('table')\n",
    "        prox3 = prox2.find('tbody')\n",
    "        prox4 = prox3.find_all('tr')\n",
    "        for i in prox4:\n",
    "            atributes = i.find_all('td')\n",
    "            self.proxies.append(ProxyInList(atributes[0].text, atributes[1].text, atributes[2].text, atributes[4].text, atributes[5].text, atributes[6].text, atributes[7].text))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self.proxies)\n",
    "    \n",
    "    @property\n",
    "    def withHttps(self):\n",
    "        listed = [x for x in self.proxies if x.https == 'yes']\n",
    "        lss = []\n",
    "        for e in listed:\n",
    "            lss.append(e.ip_port)\n",
    "        return lss\n",
    "        \n",
    "    @property\n",
    "    def giveMeProxies(self):\n",
    "        lss = self.withHttps\n",
    "        return random.choice(lss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Proxies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = p.giveMeProxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'143.198.213.77:1080'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proxy:+++ 143.198.213.77:1080 +++\n",
      "Error with requests\n",
      "Error with urllib\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "url1 = 'https://iopscience.iop.org/nsearch?terms=raman&nextPage=2&previousPage=-1&currentPage=1&searchDatePeriod=anytime&orderBy=relevance&pageLength=50'\n",
    "url2 = 'https://www.nature.com/search?q=raman+data+science&order=relevance&page=2'\n",
    "url3 = 'https://link.springer.com/search?query=raman'\n",
    "wiki = 'https://en.wikipedia.org/wiki/Python_(programming_language)'\n",
    "\n",
    "urls = [url1, url2, url3]\n",
    "\n",
    "user_agent1 = 'Mac OS X10/Safari browser: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/601.3.9 (KHTML, like Gecko) Version/9.0.2 Safari/601.3.9'\n",
    "user_agent2 = 'Windows 10/Chrome browser: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36'\n",
    "user_agent3 = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36'\n",
    "\n",
    "user_agents = [user_agent1, user_agent2, user_agent3]\n",
    "\n",
    "random_user_agent = random.choice(user_agents)\n",
    "random_url = random.choice(urls)\n",
    "\n",
    "\n",
    "# In the following code we try to make a request to the page using three\n",
    "# different modules: requests, urllib and selenium\n",
    "\n",
    "\n",
    "import requests\n",
    "import urllib.request\n",
    "from selenium import webdriver\n",
    "\n",
    "pro = Proxies()\n",
    "proxy = pro.giveMeProxies\n",
    "\n",
    "print('Proxy:+++', proxy.replace(' ',''),'+++')\n",
    "# Selecting a random ip and port from the list of proxies\n",
    "\n",
    "def req_only_requests(url, user_agent):\n",
    "    headers = {'User-Agent': user_agent}\n",
    "    page = requests.get(url, headers=headers, proxies={'https': proxy})\n",
    "    print(page.status_code)\n",
    "\n",
    "def req_only_urllib(url, user_agent):\n",
    "    req = urllib.request.Request(url, headers={'User-Agent': user_agent}, proxy=proxy)\n",
    "    page = urllib.request.urlopen(req)\n",
    "    print(page.status)\n",
    "try:\n",
    "    req_only_requests(wiki, random_user_agent)\n",
    "except:\n",
    "    print('Error with requests')\n",
    "try:\n",
    "    req_only_urllib(wiki, random_user_agent)\n",
    "except:\n",
    "    print('Error with urllib')\n",
    "\n",
    "# def requesting_with_three_modules(url, user_agent):\n",
    "\n",
    "#     headers = {'User-Agent': user_agent}\n",
    "#     pro = Proxies()\n",
    "#     proxy = pro.giveMeProxies().ip_port\n",
    "\n",
    "    \n",
    "#     page = requests.get(url, headers=headers, proxies={'http': proxy, 'https': proxy})\n",
    "#     print(page.status_code)\n",
    "\n",
    "    \n",
    "\n",
    "#     req = urllib.request.Request(url, headers={'User-Agent': user_agent}, proxy=proxy)\n",
    "#     page = urllib.request.urlopen(req)\n",
    "#     print(page.status)\n",
    "\n",
    "    \n",
    "\n",
    "#     chrome_options = webdriver.ChromeOptions()\n",
    "#     chrome_options.add_argument(\"--proxy-server={}\".format(proxy))\n",
    "#     chrome_options.add_argument(\"--user-agent={}\".format(random_user_agent))\n",
    "#     driver = webdriver.Chrome(chrome_options=chrome_options)\n",
    "#     driver.get(url)\n",
    "#     print(driver.title)\n",
    "#     driver.close()\n",
    "\n",
    "# requesting_with_three_modules(wiki, random_user_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class SciScraper2(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        # self.prox = Proxies()\n",
    "        self.history = []\n",
    "        \n",
    "        self.url ='https://iopscience.iop.org/nsearch?terms=raman&nextPage=2&previousPage=-1&currentPage=1&searchDatePeriod=anytime&orderBy=relevance&pageLength=20'\n",
    "        # self.url = 'https://en.wikipedia.org/wiki/Structural_formula'\n",
    "\n",
    "        # TODO : Change the headers dybamically\n",
    "\n",
    "        user_agent1 = 'Mac OS X10/Safari browser: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/601.3.9 (KHTML, like Gecko) Version/9.0.2 Safari/601.3.9'\n",
    "        user_agent2 = 'Windows 10/Chrome browser: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36'\n",
    "        user_agent3 = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36'\n",
    "        \n",
    "        header = {\"User-Agent\": user_agent2}\n",
    "\n",
    "        # TODO : Manage history of searched terms\n",
    "        self.current = requests.get(self.url, headers = header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper = SciScraper2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have the content of the page inside the variable 'current'\n",
    "# we can use BeautifulSoup to parse the html\n",
    "\n",
    "soup = BeautifulSoup(scraper.current.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "articulos = soup.find_all('div', class_='art-list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.ResultSet"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(articulos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Tag"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(articulos[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = articulos[0].find_all('div', class_='art-list-item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"art-list-item\">\n",
       "<div class=\"art-list-item-body\">\n",
       "<div class=\"eyebrow d-ib\">\n",
       "<span>Journal article</span>\n",
       "</div>\n",
       "<h2 class=\"art-list-item-title\"><a href=\"/article/10.1070/QE1977v007n12ABEH008267\">\n",
       "            A comparison of inverse Raman scattering and coherent\n",
       "anti-Stokes Raman scattering at and near electron\n",
       "resonance</a></h2>\n",
       "<p class=\"small art-list-item-meta\"><span data-authors=\"\"><span itemprop=\"author\" itemtype=\"http://schema.org/Person\">W Werncke</span>, <span itemprop=\"author\" itemtype=\"http://schema.org/Person\">A Lau</span>, <span itemprop=\"author\" itemtype=\"http://schema.org/Person\">M Pfeiffer</span>, <span itemprop=\"author\" itemtype=\"http://schema.org/Person\">K Lenz</span> and <span itemprop=\"author\" itemtype=\"http://schema.org/Person\">H J Weigmann</span></span></p>\n",
       "<p class=\"small art-list-item-meta\">\n",
       "            1977<em> Sov. J. Quantum Electron.</em><b> 7</b> 1464\n",
       "             \n",
       "            <a class=\"mr-2\" href=\"https://doi.org/10.1070/QE1977v007n12ABEH008267\">https://doi.org/10.1070/QE1977v007n12ABEH008267</a>\n",
       "</p>\n",
       "<div class=\"reveal-container reveal-closed reveal-plus-icon\">\n",
       "<div class=\"art-list-item-tools small\">\n",
       "<a class=\"reveal-trigger mr-2\" data-link-purpose-append=\"A comparison of inverse Raman scattering and coherent\n",
       "anti-Stokes Raman scattering at and near electron\n",
       "resonance\" data-link-purpose-append-open=\"A comparison of inverse Raman scattering and coherent\n",
       "anti-Stokes Raman scattering at and near electron\n",
       "resonance\" data-reveal-label-alt=\"Close abstract\" data-reveal-text=\"Open abstract\" href=\"\">Open abstract</a>\n",
       "<a class=\"mr-2\" href=\"/article/10.1070/QE1977v007n12ABEH008267/meta\"> <span class=\"icon-article\"></span>View article<span class=\"offscreen-hidden\">, A comparison of inverse Raman scattering and coherent\n",
       "anti-Stokes Raman scattering at and near electron\n",
       "resonance</span></a>\n",
       "<a class=\"mr-2 nowrap\" href=\"/article/10.1070/QE1977v007n12ABEH008267/pdf\" rel=\"noopener\" target=\"_blank\"><span class=\"icon-file-pdf\"></span>PDF<span class=\"offscreen-hidden\">, A comparison of inverse Raman scattering and coherent\n",
       "anti-Stokes Raman scattering at and near electron\n",
       "resonance</span></a>\n",
       "</div>\n",
       "<div class=\"reveal-content\">\n",
       "<div class=\"article-text view-text-small\"><p>\n",
       "A comparison is made of inverse Raman scattering (IRS) and coherent anti-Stokes Raman scattering\n",
       "(CARS) from the point of view of their applicability in Raman-spectroscopic investigations of liquid media.\n",
       "Important aspects in this context are the detection limit of weak Raman lines, the comparability of their\n",
       "profiles with those of spontaneous Raman scattering (SPRS) lines, and the feasibility of utilizing the\n",
       "resonant Raman effect. Both methods were implemented using experimental setups with two pulsed lasers\n",
       "(narrow- and broad-band).\n",
       "</p></div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</div>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we save the info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.117.239.22:3128\n"
     ]
    },
    {
     "ename": "URLError",
     "evalue": "<urlopen error [Errno 110] Connection timed out>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1348\u001b[0m     h\u001b[39m.\u001b[39;49mrequest(req\u001b[39m.\u001b[39;49mget_method(), req\u001b[39m.\u001b[39;49mselector, req\u001b[39m.\u001b[39;49mdata, headers,\n\u001b[1;32m   1349\u001b[0m               encode_chunked\u001b[39m=\u001b[39;49mreq\u001b[39m.\u001b[39;49mhas_header(\u001b[39m'\u001b[39;49m\u001b[39mTransfer-encoding\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m   1350\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m err: \u001b[39m# timeout error\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1282\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1282\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1328\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1327\u001b[0m     body \u001b[39m=\u001b[39m _encode(body, \u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1328\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendheaders(body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1277\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[39mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1277\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_output(message_body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1037\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1036\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1037\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(msg)\n\u001b[1;32m   1039\u001b[0m \u001b[39mif\u001b[39;00m message_body \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1040\u001b[0m \n\u001b[1;32m   1041\u001b[0m     \u001b[39m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:975\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_open:\n\u001b[0;32m--> 975\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnect()\n\u001b[1;32m    976\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1447\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1445\u001b[0m \u001b[39m\"\u001b[39m\u001b[39mConnect to a host on a given (SSL) port.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1447\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mconnect()\n\u001b[1;32m   1449\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tunnel_host:\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:941\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    940\u001b[0m sys\u001b[39m.\u001b[39maudit(\u001b[39m\"\u001b[39m\u001b[39mhttp.client.connect\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mport)\n\u001b[0;32m--> 941\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_connection(\n\u001b[1;32m    942\u001b[0m     (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhost,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mport), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msource_address)\n\u001b[1;32m    943\u001b[0m \u001b[39m# Might fail in OSs that don't implement TCP_NODELAY\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:845\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 845\u001b[0m     \u001b[39mraise\u001b[39;00m err\n\u001b[1;32m    846\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    847\u001b[0m     \u001b[39m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:833\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    832\u001b[0m     sock\u001b[39m.\u001b[39mbind(source_address)\n\u001b[0;32m--> 833\u001b[0m sock\u001b[39m.\u001b[39;49mconnect(sa)\n\u001b[1;32m    834\u001b[0m \u001b[39m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: [Errno 110] Connection timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/jupyter/solt/scicrapy2/scicrapy/scicrapy2.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jupyter/solt/scicrapy2/scicrapy/scicrapy2.ipynb#X16sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m opener \u001b[39m=\u001b[39m urllib\u001b[39m.\u001b[39mrequest\u001b[39m.\u001b[39mbuild_opener(proxy_handler)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jupyter/solt/scicrapy2/scicrapy/scicrapy2.ipynb#X16sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m req \u001b[39m=\u001b[39m urllib\u001b[39m.\u001b[39mrequest\u001b[39m.\u001b[39mRequest(url2, headers\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mUser-Agent\u001b[39m\u001b[39m'\u001b[39m: ua1})\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/jupyter/solt/scicrapy2/scicrapy/scicrapy2.ipynb#X16sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m page \u001b[39m=\u001b[39m opener\u001b[39m.\u001b[39;49mopen(req)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jupyter/solt/scicrapy2/scicrapy/scicrapy2.ipynb#X16sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mprint\u001b[39m(page\u001b[39m.\u001b[39mstatus)\n",
      "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    516\u001b[0m     req \u001b[39m=\u001b[39m meth(req)\n\u001b[1;32m    518\u001b[0m sys\u001b[39m.\u001b[39maudit(\u001b[39m'\u001b[39m\u001b[39murllib.Request\u001b[39m\u001b[39m'\u001b[39m, req\u001b[39m.\u001b[39mfull_url, req\u001b[39m.\u001b[39mdata, req\u001b[39m.\u001b[39mheaders, req\u001b[39m.\u001b[39mget_method())\n\u001b[0;32m--> 519\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open(req, data)\n\u001b[1;32m    521\u001b[0m \u001b[39m# post-process response\u001b[39;00m\n\u001b[1;32m    522\u001b[0m meth_name \u001b[39m=\u001b[39m protocol\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_response\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[1;32m    535\u001b[0m protocol \u001b[39m=\u001b[39m req\u001b[39m.\u001b[39mtype\n\u001b[0;32m--> 536\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_chain(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_open, protocol, protocol \u001b[39m+\u001b[39;49m\n\u001b[1;32m    537\u001b[0m                           \u001b[39m'\u001b[39;49m\u001b[39m_open\u001b[39;49m\u001b[39m'\u001b[39;49m, req)\n\u001b[1;32m    538\u001b[0m \u001b[39mif\u001b[39;00m result:\n\u001b[1;32m    539\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[39mfor\u001b[39;00m handler \u001b[39min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    497\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhttps_open\u001b[39m(\u001b[39mself\u001b[39m, req):\n\u001b[0;32m-> 1391\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_open(http\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mHTTPSConnection, req,\n\u001b[1;32m   1392\u001b[0m         context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_context, check_hostname\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_hostname)\n",
      "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:1351\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         h\u001b[39m.\u001b[39mrequest(req\u001b[39m.\u001b[39mget_method(), req\u001b[39m.\u001b[39mselector, req\u001b[39m.\u001b[39mdata, headers,\n\u001b[1;32m   1349\u001b[0m                   encode_chunked\u001b[39m=\u001b[39mreq\u001b[39m.\u001b[39mhas_header(\u001b[39m'\u001b[39m\u001b[39mTransfer-encoding\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m   1350\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m err: \u001b[39m# timeout error\u001b[39;00m\n\u001b[0;32m-> 1351\u001b[0m         \u001b[39mraise\u001b[39;00m URLError(err)\n\u001b[1;32m   1352\u001b[0m     r \u001b[39m=\u001b[39m h\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m   1353\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error [Errno 110] Connection timed out>"
     ]
    }
   ],
   "source": [
    "# In this notebook, we will create a scrapping tool for scientific articles\n",
    "# Importing the libraries\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "p = Proxies()\n",
    "pp = p.giveMeProxies\n",
    "print(pp)\n",
    "\n",
    "url1 ='https://iopscience.iop.org/nsearch?terms=textil&nextPage=2&previousPage=-1&currentPage=1&searchDatePeriod=anytime&orderBy=relevance&pageLength=10'\n",
    "url2 = 'https://en.wikipedia.org/wiki/Structural_formula'\n",
    "\n",
    "# Getting the webpage, with headers to make sure we get the results we require\n",
    "# We create the headers as a dictionary\n",
    "\n",
    "\n",
    "ua1 = 'Mac OS X10/Safari browser: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/601.3.9 (KHTML, like Gecko) Version/9.0.2 Safari/601.3.9'\n",
    "ua2 = 'Windows 10/Chrome browser: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36'\n",
    "ua3 = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36'\n",
    "\n",
    "\n",
    "proxy_handler = urllib.request.ProxyHandler({'https': pp})\n",
    "opener = urllib.request.build_opener(proxy_handler)\n",
    "req = urllib.request.Request(url2, headers={'User-Agent': ua1})\n",
    "page = opener.open(req)\n",
    "print(page.status)\n",
    "\n",
    "\n",
    "# headers = {\"User-Agent\": ua1}\n",
    "# page = requests.get(url1, headers=headers, proxies=proxies)\n",
    "\n",
    "# soup = BeautifulSoup(page.content, 'html.parser')\n",
    "# # arts = soup.find_all('div', class_=\"art-list-item-body\")\n",
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not Response",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/jupyter/solt/scicrapy2/scicrapy/scicrapy2.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jupyter/solt/scicrapy2/scicrapy/scicrapy2.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mpage.html\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jupyter/solt/scicrapy2/scicrapy/scicrapy2.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         file\u001b[39m.\u001b[39mwrite(page)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jupyter/solt/scicrapy2/scicrapy/scicrapy2.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m save(page\u001b[39m=\u001b[39;49mpage)\n",
      "\u001b[1;32m/home/jupyter/solt/scicrapy2/scicrapy/scicrapy2.ipynb Cell 3\u001b[0m in \u001b[0;36msave\u001b[0;34m(page)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jupyter/solt/scicrapy2/scicrapy/scicrapy2.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msave\u001b[39m(page):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jupyter/solt/scicrapy2/scicrapy/scicrapy2.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mpage.html\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jupyter/solt/scicrapy2/scicrapy/scicrapy2.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         file\u001b[39m.\u001b[39;49mwrite(page)\n",
      "\u001b[0;31mTypeError\u001b[0m: write() argument must be str, not Response"
     ]
    }
   ],
   "source": [
    "# Saving this page as an html file\n",
    "\n",
    "def save(page):\n",
    "    with open('page.html', 'w') as file:\n",
    "        file.write(page)\n",
    "\n",
    "save(page=page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We select an article to organize our tool\n",
    "\n",
    "art = arts[1]\n",
    "\n",
    "# We get the title and all other information and set it to a dictionary\n",
    "# title = art.find('h2', class_=\"art-list-item-title\")\n",
    "# Now we replace the following characters in the title with nothing \\r \\n and double spaces\n",
    "# r = ''\n",
    "# for char in title.text:\n",
    "#     if char in ['\\r', '\\n']:\n",
    "#         pass\n",
    "#     else:\n",
    "#         r += char\n",
    "# r = r.replace('  ', '')\n",
    "# r\n",
    "\n",
    "\n",
    "\n",
    "# authors = art.find_all('span', itemprop=\"author\")\n",
    "# auths = []\n",
    "# for a in authors:\n",
    "#     auths.append(a.text)\n",
    "# auths\n",
    "\n",
    "\n",
    "\n",
    "# journal = art.find_all('p', class_=\"small art-list-item-meta\")\n",
    "\n",
    "\n",
    "\n",
    "# date = art.find('div', class_=\"art-list-item-date\").text\n",
    "\n",
    "\n",
    "\n",
    "# abstract = art.find('div', class_=\"article-text view-text-small\").text.strip()\n",
    "# # <div class=\"reveal-content\">\n",
    "# # <div class=\"article-text view-text-small\">\n",
    "# abstract\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# link = art.find('a', class_=\"art-list-item-link\")['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'text'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/jupyter/solt/scicrapy2/scicrapy/scicrapy2.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jupyter/solt/scicrapy2/scicrapy/scicrapy2.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m abstract\u001b[39m.\u001b[39;49mtext\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/bs4/element.py:2289\u001b[0m, in \u001b[0;36mResultSet.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2287\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[1;32m   2288\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Raise a helpful exception to explain a common code fix.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2289\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m   2290\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mResultSet object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. You\u001b[39m\u001b[39m'\u001b[39m\u001b[39mre probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m key\n\u001b[1;32m   2291\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: ResultSet object has no attribute 'text'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "abstract.text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
