{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "from urllib   import request\n",
    "from time     import sleep\n",
    "from bs4      import BeautifulSoup\n",
    "\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "\n",
    "# Links for IOP search\n",
    "\n",
    "IOP_S  = \"https://iopscience.iop.org/nsearch?terms=\"\n",
    "IOP_E  = \"&nextPage=2&previousPage=-1&currentPage=\"\n",
    "IOP_P  = \"&searchDatePeriod=anytime&orderBy=relevance&pageLength=50\"\n",
    "\n",
    "# Links for NATURE search\n",
    "\n",
    "NANO_S = 'https://nano.nature.com/search?term=freeText%3A'\n",
    "NANO_E = '&sort-by=relevance&page-number='\n",
    "NANO_P = '&workflow=article'\n",
    "\n",
    "\n",
    "\"\"\"===============================================================================================================================\"\"\"\n",
    "\n",
    "# -format- returns a string that can be readed as a query to IOP or NANO\n",
    "\n",
    "def format(query):\n",
    "    pre_form = query.split(\" \")\n",
    "    return \"+\".join(pre_form)\n",
    "\n",
    "\n",
    "\"\"\"===============================================================================================================================\"\"\"\n",
    "\n",
    "# Some pages may have problems if requested with -urllib- or -requests-, SwitchKitchen is implemented to\n",
    "# switch the way we obtain a BeautifulSoup object\n",
    "\n",
    "\n",
    "def SwitchKitchen(uri, kitchen = \"requests\", parse = \"lxml\"):\n",
    "\n",
    "    # Request with --requests.get(url)--\n",
    "\n",
    "    if   kitchen == \"requests\":\n",
    "         response = requests.get(uri)\n",
    "         soup     = BeautifulSoup(response.text, parse)\n",
    "\n",
    "    elif kitchen == \"urllib\":\n",
    "\n",
    "    # Request with --request.urlopen(url)--\n",
    "\n",
    "         response = request.urlopen(uri)\n",
    "         soup     = BeautifulSoup(response, parse)\n",
    "    else:\n",
    "        raise Exception(\"Problema en la elección del método mara obtener la respuesta del servidor.\")\n",
    "    return soup;\n",
    "\n",
    "\"\"\"===============================================================================================================================\"\"\"\n",
    "\n",
    "# /Souparticles : Returns a list of BeautifulSoup objects that contain articles\n",
    "\n",
    "# /material     : Is a str. containing the search term\n",
    "# /page         : The page in which we are searching\n",
    "# /max_try      : The maximum tries before givin up, commonly this is a result of a 400 status response from the server\n",
    "# /slpy         : Is the time between requests, recommended to prevent overloading requested server\n",
    "\n",
    "\n",
    "def souparticlesIOP(query, page, max_int = 5, slpy = 3):\n",
    "    # At the beginning our IOP Soup is a None object\n",
    "    soupIOP = None\n",
    "    ints  = 0\n",
    "\n",
    "    while ints<max_int:    \n",
    "    # We try to catch some content from the server\n",
    "\n",
    "        try:\n",
    "            uri      = IOP_S+ format(query) + IOP_E + str(page) + IOP_P\n",
    "            # If we catch a 200 response we can make a Beautifoul Soup (BS), parsing with lxml\n",
    "            soupIOP  = SwitchKitchen(uri,kitchen = \"urllib\")\n",
    "            break\n",
    "        except:\n",
    "            # If we catch an error, we can retry\n",
    "            print(\"Reintentando pag: \" + str(page))\n",
    "            sleep(slpy)\n",
    "            pass\n",
    "        finally:\n",
    "            ints +=1\n",
    "    \n",
    "    # For soupIOP == None this process needs to be repeated\n",
    "    if(soupIOP==None):\n",
    "        print( \"Por favor reinicie la busqueda para pag: \" + str(page))\n",
    "        return None;\n",
    "    else:\n",
    "        # Returning the articles in a BS object\n",
    "        print(\"Añadida pag: \" + str(page))\n",
    "        return soupIOP.find_all('div', {\"class\" : \"art-list-item-body\"})\n",
    "\n",
    "\"\"\"===============================================================================================================================\"\"\"\n",
    "\n",
    "def souparticlesNANO(query, page, max_int = 5, slpy = 3):\n",
    "    nanosoup = None\n",
    "    ints=0\n",
    "    while ints<max_int:\n",
    "        try:\n",
    "            uri      = NANO_S+'\"'+format(query)+'\"'+NANO_E+str(page)+NANO_P\n",
    "            nanosoup = SwitchKitchen(uri, kitchen = \"requests\")\n",
    "            break\n",
    "        except:\n",
    "            print(\"Reintentando pag: \" + str(page))\n",
    "            sleep(slpy)\n",
    "            pass\n",
    "        finally:\n",
    "            ints +=1\n",
    "    if(nanosoup==None):\n",
    "        print( \"Por favor reinicie la busqueda para pag: \" + str(page))\n",
    "        return None;\n",
    "    else:\n",
    "        print(\"Añadida pag: \" + str(page))\n",
    "        return nanosoup.find_all('li', {\"class\" : \"Results_listItem\" })\n",
    "\n",
    "\"\"\"===============================================================================================================================\"\"\"\n",
    "\n",
    "# -Pages- returns a list of pages, each element contains the articles within that page\n",
    "\n",
    "def PagesIOP(query):\n",
    "    raw_pages   = []\n",
    "    init_uri  = IOP_S+ format(query) + IOP_E + str(1) + IOP_P\n",
    "    init_soup = SwitchKitchen(init_uri,kitchen = \"urllib\")\n",
    "    end_pages = init_soup.findChild(\"p\",{\"class\":\"pgs small\"}).get_text().split(\" \")[2]\n",
    "    for i in range(1, int(end_pages)+1):\n",
    "        raw_pages.append(souparticlesIOP(query, i))\n",
    "    return raw_pages;\n",
    "\n",
    "\"\"\"===============================================================================================================================\"\"\"\n",
    "\n",
    "def PagesNANO(query, cut = 12):\n",
    "    raw_pages = []\n",
    "    init_uri  = NANO_S+'\"'+format(query)+'\"'+NANO_E+str(1)+NANO_P\n",
    "    init_soup = SwitchKitchen(init_uri,kitchen = \"requests\")\n",
    "    end_pages = init_soup.findChild(\"span\",{\"class\":\"Pagination_numOfPages\"})\n",
    "    num_of_pgs= int(end_pages.get_text().replace(\"\\n\",\"\").replace(\" \",\"\").replace(\",\",\"\"))\n",
    "    if num_of_pgs<12:\n",
    "        for i in range(1,num_of_pgs+1):\n",
    "            raw_pages.append(souparticlesNANO(query, i))\n",
    "    else:\n",
    "        for i in range(1, cut + 1 ):\n",
    "            raw_pages.append(souparticlesNANO(query, i))\n",
    "    return raw_pages;\n",
    "\n",
    "\"\"\"===============================================================================================================================\"\"\"\n",
    "\n",
    "# -stringify- returns a list of articles, each article containing it´s features, that can be readed as normal strings\n",
    "\n",
    "def stringifyIOP(raw_pages):\n",
    "    arts_db = []\n",
    "    for page in raw_pages:\n",
    "        for element in page:\n",
    "            try:\n",
    "                title     =     element.findChild('h2' , {\"class\"   : \"art-list-item-title\"}).findChild(\"a\")          # 0 title\n",
    "                abstract  =     element.findChild('div', {\"class\"   : \"article-text view-text-small\"}).findChild(\"p\") # 1 abstract\n",
    "                DOI       =     element.findChild('a'  , {\"class\"   : \"mr-2\"})                                        # 2 DOI\n",
    "                journal   =     element.findChild('em')                                                               # 3 Journal\n",
    "                #vol       =     element.findChild('b')                                                              \n",
    "                authors   =     element.find_all('span', {\"itemprop\": \"author\"})                                      # 4 auths\n",
    "\n",
    "                yearfind  =     element.find_all(\"p\"   , { \"class\" :\"small art-list-item-meta\"})                      # 5 year\n",
    "                year      =     int(yearfind[1].text[14:19])\n",
    "\n",
    "                arts_db.append([title.text ,abstract.text, DOI.text, journal.text,[auth.getText() for auth in authors], year])\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    return arts_db;\n",
    "\n",
    "\n",
    "\"\"\"===============================================================================================================================\"\"\"\n",
    "\n",
    "def stringifyNANO(raw_pages):\n",
    "    arts_db = []\n",
    "    for page in raw_pages:\n",
    "        for element in page:\n",
    "            try:\n",
    "                title       =     element.findChild(\"h2\").getText().replace(\"\\n\",\"\")                                # 0 Title\n",
    "                miscel      =     element.find_all(\"p\")\n",
    "\n",
    "                abstract    =     miscel[1].getText()                                                               # 1 Abstract\n",
    "                DOI         =     element.findChild('div', {\"class\": \"Doi\"}).getText()                              # 2 DOI\n",
    "                journal     =     miscel[0].findChild(\"strong\").getText()                                           # 3 Journal\n",
    "\n",
    "                #cited       =     miscel[2].getText()\n",
    "\n",
    "                authstag    =     element.findChild(\"ul\", {\"class\":\"PipeSepList Author\"})                           # 4 Auths\n",
    "                authors_tag =     authstag.find_all(\"li\")\n",
    "                authors_str = [author.getText().replace(\"\\n\",\"\") for author in authors_tag]\n",
    "\n",
    "                begi        =     miscel[0].getText().find(\"(\")\n",
    "                year        =     miscel[0].getText()[begi+1:begi+5]                                                # 5 Year\n",
    "\n",
    "                arts_db.append([title, abstract, DOI, journal, authors_str, year])\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    return arts_db;\n",
    "\n",
    "\"\"\"===============================================================================================================================\"\"\"\n",
    "\n",
    "# -query- returns a list of articles related to the search-term term*, note that this returns both IOP and NANO articles\n",
    "\n",
    "def query(terms):\n",
    "    all_arts = []\n",
    "\n",
    "    query_raw_iop  = PagesIOP(terms)\n",
    "    query_raw_nano = PagesNANO(terms)\n",
    "\n",
    "    IOP_DB         = stringifyIOP(query_raw_iop)\n",
    "    NANO_DB        = stringifyNANO(query_raw_nano)\n",
    "\n",
    "    for article in NANO_DB:\n",
    "        all_arts.append(article)\n",
    "    for article in IOP_DB:\n",
    "        all_arts.append(article)\n",
    "\n",
    "    return all_arts;\n",
    "\n",
    "\"\"\"===============================================================================================================================\"\"\"\n",
    "\n",
    "def search_kwords(arts, kwords):\n",
    "    candidates = []\n",
    "    count = 0\n",
    "    for art in arts:\n",
    "        if kwords in art[1]:\n",
    "            candidates.append(art)\n",
    "            count +=1\n",
    "    print(\"Coincidences: \" +str(count))\n",
    "    return candidates;\n",
    "\n",
    "\n",
    "\"\"\"===============================================================================================================================\"\"\"\n",
    "\n",
    "\n",
    "def pandas_dataframe(all_arts, name):\n",
    "    test_arts = {}\n",
    "    for i in range(0,6):\n",
    "        ls = []\n",
    "        for j in range(0,len(all_arts)):\n",
    "            ls.append(all_arts[j][i])\n",
    "        if i == 0:\n",
    "            test_arts.update(Title        = ls)\n",
    "        elif i == 1:\n",
    "            test_arts.update(Abstract     = ls)\n",
    "        elif i == 2:\n",
    "            test_arts.update(DOI          = ls)\n",
    "        elif i == 3:\n",
    "            test_arts.update(Journal      = ls)\n",
    "        elif i == 4:\n",
    "            test_arts.update(Auths        = ls)\n",
    "        else:\n",
    "            test_arts.update(Year         = ls)\n",
    "    pd.DataFrame(test_arts).to_pickle(\"mispepinillos/{}.pkl\".format(name))\n",
    "    return pd.DataFrame(test_arts);\n",
    "\n",
    "# To read a pandas dataframe local_datarame= pandas.read_pickle(\"folder/file.pkl\")\n",
    "\n",
    "\"\"\"===============================================================================================================================\"\"\"\n",
    "\n",
    "def geve_art(art_num, dataframe):\n",
    "    print(dataframe.iloc[art_num][\"Abstract\"].replace(\"\\n\", \"\"))\n",
    "    print(\"\\n\")\n",
    "    print(dataframe.iloc[art_num][\"Title\"].replace(\"\\n\", \"\"))\n",
    "    print(\"\\n\")\n",
    "    print(dataframe.iloc[art_num][\"Year\"])\n",
    "    print(\"\\n\")\n",
    "    print(dataframe.iloc[art_num][\"DOI\"])\n",
    "    print(\"\\n\")\n",
    "    print(dataframe.iloc[art_num][\"Journal\"])\n",
    "    return;\n",
    "\n",
    "\"\"\"===============================================================================================================================\"\"\"\n",
    "\n",
    "def dbsearch(word, db):\n",
    "    ls = []\n",
    "    for i in range(0,len(db)):\n",
    "        if word in db.iloc[i][\"Abstract\"].lower():\n",
    "            ls.append(i)\n",
    "        else:\n",
    "            pass\n",
    "    new_db = db.iloc [ls]\n",
    "    new_index = len(new_db)\n",
    "    new_db.set_index(np.arange(0,new_index),inplace=True)\n",
    "    return new_db; \n",
    "\n",
    "\"\"\"===============================================================================================================================\"\"\"\n",
    "\n",
    "def cite_manager(art, com, db = pd.Series([])):\n",
    "    if db.empty:\n",
    "        art = art.to_frame().transpose()\n",
    "        art = art.assign(comment = [com])\n",
    "        return art;\n",
    "    else:\n",
    "        art = art.to_frame().transpose()\n",
    "        art = art.assign(comment = [com])\n",
    "        db  = pd.concat([db,art], ignore_index=True, copy=False)\n",
    "        return db;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Añadida pag: 1\n",
      "Añadida pag: 2\n",
      "Añadida pag: 3\n",
      "Añadida pag: 4\n",
      "Añadida pag: 5\n",
      "Añadida pag: 6\n",
      "Añadida pag: 7\n",
      "Añadida pag: 8\n",
      "Añadida pag: 9\n",
      "Añadida pag: 10\n",
      "Añadida pag: 11\n",
      "Añadida pag: 1\n",
      "Añadida pag: 2\n",
      "Añadida pag: 3\n",
      "Añadida pag: 4\n",
      "Añadida pag: 5\n",
      "Añadida pag: 6\n",
      "Añadida pag: 7\n",
      "Añadida pag: 8\n",
      "Añadida pag: 9\n",
      "Añadida pag: 10\n",
      "Añadida pag: 11\n",
      "Añadida pag: 12\n"
     ]
    }
   ],
   "source": [
    "# Our first query returns a list with all the pappers related\n",
    "\n",
    "first_query = query(\"electronics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "608"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let´s check for the content\n",
    "# Outputs 608 pappers\n",
    "\n",
    "len(first_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we convert this query to a dataframe object, first argument is the query object \n",
    "# and the string argument is the name of the db\n",
    "\n",
    "db_query = pandas_dataframe(first_query, \"pappers_on_electronics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 608 entries, 0 to 607\n",
      "Data columns (total 6 columns):\n",
      "Title       608 non-null object\n",
      "Abstract    608 non-null object\n",
      "DOI         608 non-null object\n",
      "Journal     608 non-null object\n",
      "Auths       608 non-null object\n",
      "Year        608 non-null object\n",
      "dtypes: object(6)\n",
      "memory usage: 28.6+ KB\n"
     ]
    }
   ],
   "source": [
    "db_query.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Journal</th>\n",
       "      <th>Auths</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Living electronics</td>\n",
       "      <td>Living electronics that converges the unique f...</td>\n",
       "      <td>10.1007/s12274-019-2570-x</td>\n",
       "      <td>Nano Research</td>\n",
       "      <td>[Yixin Zhang, Leo Huan-Hsuan Hsu, Xiaocheng Ji...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Epidermal Electronics</td>\n",
       "      <td>We report classes of electronic systems that a...</td>\n",
       "      <td>10.1126/science.1206157</td>\n",
       "      <td>Science</td>\n",
       "      <td>[Dae-Hyeong Kim, Nanshu Lu, Rui Ma, Yun-Soung ...</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cool electronics</td>\n",
       "      <td></td>\n",
       "      <td>10.1038/nmat4194</td>\n",
       "      <td>Nature Materials</td>\n",
       "      <td>[Jungwan Cho, Kenneth E. Goodson]</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Paper Electronics</td>\n",
       "      <td>Paper is ubiquitous in everyday life and a tru...</td>\n",
       "      <td>10.1002/adma.201004692</td>\n",
       "      <td>Advanced Materials</td>\n",
       "      <td>[Daniel Tobjörk, Ronald Österbacka]</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Organic Electronics</td>\n",
       "      <td>20</td>\n",
       "      <td>10.1002/adma.201205216</td>\n",
       "      <td>Advanced Materials</td>\n",
       "      <td>[Iain McCulloch]</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>Analysis of Laser-Diode and Lamp Optical Pump...</td>\n",
       "      <td>The time evolution of populations of the groun...</td>\n",
       "      <td>https://doi.org/10.1088/0256-307X/30/2/023201</td>\n",
       "      <td>Chinese Phys. Lett.</td>\n",
       "      <td>[Guo Jian (郭简), Wang Yan-Hui (王延辉)]</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>Etch-Back Planarization Technique for Multile...</td>\n",
       "      <td>\\n  In order to realize multilevel interconne...</td>\n",
       "      <td>https://doi.org/10.1143/JJAP.27.280</td>\n",
       "      <td>Jpn. J. Appl. Phys.</td>\n",
       "      <td>[Shuichi Mayumi, Kazuo Fujiwara, Shuichi Nishi...</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>Enhanced Stability of All Solution-Processed ...</td>\n",
       "      <td>\\n Enhanced stability of all solution-process...</td>\n",
       "      <td>https://doi.org/10.1143/JJAP.51.091602</td>\n",
       "      <td>Jpn. J. Appl. Phys.</td>\n",
       "      <td>[Jeong In Han, Yong-Hoon Kim, Sung Kyu Park]</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>Injection of photoelectrons into dense argon gas</td>\n",
       "      <td>The injection of photoelectrons into a gaseous...</td>\n",
       "      <td>https://doi.org/10.1088/0963-0252/20/3/034001</td>\n",
       "      <td>Plasma Sources Sci. Technol.</td>\n",
       "      <td>[A F Borghesani, P Lamp]</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>Characteristics of Ultra Thin Hf-Silicate Gat...</td>\n",
       "      <td>\\n  For the first time, the characteristics o...</td>\n",
       "      <td>https://doi.org/10.1143/JJAP.44.2447</td>\n",
       "      <td>Jpn. J. Appl. Phys.</td>\n",
       "      <td>[Kou-Chen Liu, Sidhu Maikap, Pang-Shiu Chen]</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  \\\n",
       "0                                   Living electronics   \n",
       "1                                Epidermal Electronics   \n",
       "2                                     Cool electronics   \n",
       "3                                    Paper Electronics   \n",
       "4                                  Organic Electronics   \n",
       "..                                                 ...   \n",
       "603   Analysis of Laser-Diode and Lamp Optical Pump...   \n",
       "604   Etch-Back Planarization Technique for Multile...   \n",
       "605   Enhanced Stability of All Solution-Processed ...   \n",
       "606   Injection of photoelectrons into dense argon gas   \n",
       "607   Characteristics of Ultra Thin Hf-Silicate Gat...   \n",
       "\n",
       "                                              Abstract  \\\n",
       "0    Living electronics that converges the unique f...   \n",
       "1    We report classes of electronic systems that a...   \n",
       "2                                                        \n",
       "3    Paper is ubiquitous in everyday life and a tru...   \n",
       "4                                                   20   \n",
       "..                                                 ...   \n",
       "603  The time evolution of populations of the groun...   \n",
       "604   \\n  In order to realize multilevel interconne...   \n",
       "605   \\n Enhanced stability of all solution-process...   \n",
       "606  The injection of photoelectrons into a gaseous...   \n",
       "607   \\n  For the first time, the characteristics o...   \n",
       "\n",
       "                                               DOI  \\\n",
       "0                        10.1007/s12274-019-2570-x   \n",
       "1                          10.1126/science.1206157   \n",
       "2                                 10.1038/nmat4194   \n",
       "3                           10.1002/adma.201004692   \n",
       "4                           10.1002/adma.201205216   \n",
       "..                                             ...   \n",
       "603  https://doi.org/10.1088/0256-307X/30/2/023201   \n",
       "604            https://doi.org/10.1143/JJAP.27.280   \n",
       "605         https://doi.org/10.1143/JJAP.51.091602   \n",
       "606  https://doi.org/10.1088/0963-0252/20/3/034001   \n",
       "607           https://doi.org/10.1143/JJAP.44.2447   \n",
       "\n",
       "                           Journal  \\\n",
       "0                    Nano Research   \n",
       "1                          Science   \n",
       "2                 Nature Materials   \n",
       "3               Advanced Materials   \n",
       "4               Advanced Materials   \n",
       "..                             ...   \n",
       "603            Chinese Phys. Lett.   \n",
       "604            Jpn. J. Appl. Phys.   \n",
       "605            Jpn. J. Appl. Phys.   \n",
       "606   Plasma Sources Sci. Technol.   \n",
       "607            Jpn. J. Appl. Phys.   \n",
       "\n",
       "                                                 Auths  Year  \n",
       "0    [Yixin Zhang, Leo Huan-Hsuan Hsu, Xiaocheng Ji...  2019  \n",
       "1    [Dae-Hyeong Kim, Nanshu Lu, Rui Ma, Yun-Soung ...  2011  \n",
       "2                    [Jungwan Cho, Kenneth E. Goodson]  2015  \n",
       "3                  [Daniel Tobjörk, Ronald Österbacka]  2011  \n",
       "4                                     [Iain McCulloch]  2013  \n",
       "..                                                 ...   ...  \n",
       "603                [Guo Jian (郭简), Wang Yan-Hui (王延辉)]  2013  \n",
       "604  [Shuichi Mayumi, Kazuo Fujiwara, Shuichi Nishi...  1988  \n",
       "605       [Jeong In Han, Yong-Hoon Kim, Sung Kyu Park]  2012  \n",
       "606                           [A F Borghesani, P Lamp]  2011  \n",
       "607       [Kou-Chen Liu, Sidhu Maikap, Pang-Shiu Chen]  2005  \n",
       "\n",
       "[608 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "name": "python37064bitd82ff44cb29b4cc0b538f5e1ebc00dce"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "version": "3.7.0-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "orig_nbformat": 2,
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
